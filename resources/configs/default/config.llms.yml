llms:
  - model: gemini-2.5-pro
    alias: gemini-2.5-pro
    provider: google
    max_tokens: 10000
    temperature: 0.1
    context_window: 1000000
    input_cost_per_mtok: 0.10
    output_cost_per_mtok: 0.40

  - model: gpt-5-mini-2025-08-07
    alias: gpt-5-mini-thinking
    provider: openai
    tag: thinking
    max_tokens: 10000
    temperature: 0.1
    context_window: 400000
    input_cost_per_mtok: 0.25
    output_cost_per_mtok: 2
    extended_reasoning:
      effort: medium
      summary: auto

  - model: claude-sonnet-4-5
    alias: sonnet-4.5
    provider: anthropic
    max_tokens: 8192
    temperature: 0.1
    context_window: 200000
    input_cost_per_mtok: 3.00
    output_cost_per_mtok: 15.00
    rate_config:
      requests_per_second: 16.67
      input_tokens_per_second: 1333.33
      output_tokens_per_second: 266.67
      check_every_n_seconds: 0.05
      max_bucket_size: 100

  - model: claude-haiku-4-5
    alias: haiku-4.5-thinking
    provider: anthropic
    tag: thinking
    max_tokens: 10000
    temperature: 1
    context_window: 200000
    input_cost_per_mtok: 1.00
    output_cost_per_mtok: 5.00
    extended_reasoning:
      type: enabled
      budget_tokens: 2000
    rate_config:
      requests_per_second: 16.67
      input_tokens_per_second: 1333.33
      output_tokens_per_second: 266.67
      check_every_n_seconds: 0.05
      max_bucket_size: 100

  - model: claude-haiku-4-5
    alias: haiku-4.5
    provider: anthropic
    max_tokens: 10000
    temperature: 0.1
    context_window: 200000
    input_cost_per_mtok: 1.00
    output_cost_per_mtok: 5.00
    rate_config:
      requests_per_second: 16.67
      input_tokens_per_second: 1333.33
      output_tokens_per_second: 266.67
      check_every_n_seconds: 0.05
      max_bucket_size: 100

  - model: eu.anthropic.claude-sonnet-4-5-20250929-v1:0
    alias: sonnet-4.5-bedrock
    provider: bedrock
    max_tokens: 5000
    temperature: 0.1
    context_window: 200000
    input_cost_per_mtok: 3.00
    output_cost_per_mtok: 15.00
    rate_config:
      requests_per_second: 16.67
      input_tokens_per_second: 1333.33
      output_tokens_per_second: 266.67
      check_every_n_seconds: 0.05
      max_bucket_size: 100

  - model: eu.anthropic.claude-sonnet-4-5-20250929-v1:0
    alias: sonnet-4.5-bedrock-thinking
    provider: bedrock
    tag: thinking
    max_tokens: 10000
    temperature: 1
    context_window: 200000
    input_cost_per_mtok: 3.00
    output_cost_per_mtok: 15.00
    extended_reasoning:
      type: enabled
      budget_tokens: 2000
    rate_config:
      requests_per_second: 16.67
      input_tokens_per_second: 1333.33
      output_tokens_per_second: 266.67
      check_every_n_seconds: 0.05
      max_bucket_size: 100

  - model: eu.anthropic.claude-haiku-4-5-20251001-v1:0
    alias: haiku-4.5-bedrock
    provider: bedrock
    max_tokens: 10000
    temperature: 0.1
    context_window: 200000
    input_cost_per_mtok: 1.00
    output_cost_per_mtok: 5.00
    rate_config:
      requests_per_second: 16.67
      input_tokens_per_second: 1333.33
      output_tokens_per_second: 266.67
      check_every_n_seconds: 0.05
      max_bucket_size: 100

  - model: deepseek-chat
    alias: deepseek-chat
    provider: deepseek
    max_tokens: 8192
    temperature: 0.1
    context_window: 64000
    input_cost_per_mtok: 0.14
    output_cost_per_mtok: 0.28

  - model: deepseek/deepseek-r1-0528-qwen3-8b
    alias: deepseek-r1-local
    provider: lmstudio
    max_tokens: 8192
    temperature: 0.1
    context_window: 64000